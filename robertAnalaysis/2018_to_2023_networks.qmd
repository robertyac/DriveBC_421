---
title: "Drive BC Network Analysis"
author:
  - name: "Robert Yacovelli"
format:
  html:
    toc: true
    embed-resources: true
    df-print: paged
editor: visual
---

# Data Loading and Initial Cleaning

## PLEASE NOTE: The data used in our repo is too big to upload to GitHub. We decided that it was best we .gitignore our data and have it on our local machines.

The data we used can be accessed through: [Acccess data here ](https://catalogue.data.gov.bc.ca/dataset/historical-drivebc-events) my analysis on this page used the years 2018 to 2023 and I renamed the files to the format `drivebceventshistXXXX` where XXXX represents the year of the csv.

```{r}
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(readr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(igraph))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(tidytext))
```

```{r cache=TRUE}
data_files <- list.files(path = "../data/", 
                        pattern = "drivebceventshist.*\\.csv",
                        full.names = TRUE)

data_files <- data_files[grep("(2018|2019|2020|2021|2022|2023)", data_files)]

col_types <- cols(
  EVENT_TYPE = col_character(),
  EVENT_SUBTYPE = col_character(),
  SEVERITY = col_character(),
  CREATED = col_character(), 
  AREA_NAME = col_character(),
  HEAD_LATITUDE = col_double(),
  HEAD_LONGITUDE = col_double(),
  ROAD_NAME = col_character()
)

# Read and combine with consistent types
road_data <- bind_rows(
  lapply(data_files, function(file) {
    read_csv(file, col_types = col_types) %>%
      select(
        EVENT_TYPE, 
        EVENT_SUBTYPE, 
        SEVERITY, 
        CREATED, 
        AREA_NAME, 
        HEAD_LATITUDE, 
        HEAD_LONGITUDE, 
        ROAD_NAME
      ) %>%
  mutate(CREATED = as.POSIXct(CREATED)) # Convert to POSIXct for date-time operations
  })
)
```

```{r}
head(road_data)
nrow(road_data)
```

# Bipartite network for incidents and time factors

```{r cache=TRUE}
#| label: fig-graph1
#| fig-width: 13
#| fig-height: 10

# Function for the creation of a bipartite network of events and time factors
create_incident_time_network <- function(data_sample) {
  incident_time_edges <- data_sample %>%
    mutate(
      hour_created = hour(as.POSIXct(CREATED)),
      time_of_day = case_when(
        hour_created >= 6 & hour_created < 12 ~ "Morning",
        hour_created >= 12 & hour_created < 18 ~ "Afternoon",
        hour_created >= 18 & hour_created < 24 ~ "Evening",
        hour_created >= 0 & hour_created < 6 ~ "Night"
      ),
      day_of_week = weekdays(CREATED),
      season = case_when(
        month(CREATED) %in% c(12, 1, 2) ~ "Winter",
        month(CREATED) %in% c(3, 4, 5) ~ "Spring",
        month(CREATED) %in% c(6, 7, 8) ~ "Summer",
        TRUE ~ "Fall"
      )
    ) %>%
    select(EVENT_TYPE, SEVERITY, AREA_NAME, time_of_day, day_of_week, season) %>%
    pivot_longer(cols = c(time_of_day, day_of_week, season), names_to = "time_factor", values_to = "time_value") %>%
    select(EVENT_TYPE, time_value)
    
  incident_time_nodes <- data.frame(
    name = unique(c(incident_time_edges$EVENT_TYPE, incident_time_edges$time_value)),
    type = c(rep(TRUE, length(unique(incident_time_edges$EVENT_TYPE))), 
             rep(FALSE, length(unique(incident_time_edges$time_value))))
  )
  
  incident_time_graph <- graph_from_data_frame(d = incident_time_edges, 
                                             vertices = incident_time_nodes, 
                                             directed = FALSE)
  return(incident_time_graph)
}

# Stratified sampling so we get a proportionate amount of events
set.seed(123) # For reproducibility of the sample
road_data_sample <- road_data %>%
  group_by(EVENT_TYPE) %>%
  sample_frac(0.001) %>% # .001 is about 1000 sample size for our data
  ungroup()

incident_time_network <- create_incident_time_network(road_data_sample)

layout <- layout_as_bipartite(incident_time_network)

plot(
  incident_time_network, 
  layout = layout, 
  vertex.label.cex = 0.6, 
  vertex.size = 5,
  vertex.label.dist = 1.5
)
```

The `sample_frac` function is used to take a stratified sample from the `road_data` dataframe, ensuring that each EVENT_TYPE is proportionally represented.

```{r}
in_degrees <- degree(incident_time_network, mode = "in")

degree_data <- data.frame(
  node = V(incident_time_network)$name,
  in_degree = in_degrees
)

# Filter to include only time values
time_values <- degree_data %>%
  filter(grepl("^[A-Z][a-z]", node))

time_values <- time_values %>%
  arrange(desc(in_degree))

ggplot(time_values, aes(x = reorder(node, in_degree), y = in_degree)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "All Event occurrences time distribution", x = "Node", y = "In-Degree") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  coord_flip() 
```

# Create a plot for each event type, using the entire dataset (2018-2023)

```{r}
#| label: fig-graph2
#| fig-width: 13
#| fig-height: 10
event_types <- unique(road_data$EVENT_TYPE)
years <- 2018:2023

# Combined data frame for all event types and years
combined_data <- do.call(rbind, lapply(event_types, function(event_type) {
  do.call(rbind, lapply(years, function(year) {
    event_data <- road_data %>%
      filter(EVENT_TYPE == event_type, year(CREATED) == year)
    
    event_network <- create_incident_time_network(event_data)
    
    event_degree_data <- data.frame(
      node = V(event_network)$name,
      in_degree = degree(event_network, mode = "in"),
      event_type = event_type,
      year = year
    )
    
    event_degree_data %>%
      filter(grepl("^[A-Z][a-z]", node))
  }))
}))

combined_data <- combined_data %>%
  group_by(event_type, node) %>%
  mutate(node_total = sum(in_degree)) %>%
  ungroup() %>%
  group_by(event_type) %>%
  mutate(total_degree = sum(in_degree)) %>%
  ungroup()

ggplot(combined_data, 
       aes(x = reorder_within(node, desc(node_total), event_type),
           y = in_degree, 
           fill = factor(year))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "In-Degree Distribution by Event Type and Year", 
       x = "Node", 
       y = "In-Degree", 
       fill = "Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ reorder(event_type, desc(total_degree)), 
             scales = "free_x",
             nrow = 2,
             ncol = 3) +
  scale_x_reordered()
```

# Region event distribution plot

```{r}
#| label: fig-graph3
#| fig-width: 13
#| fig-height: 10

region_events <- road_data %>%
  group_by(AREA_NAME, EVENT_TYPE) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(AREA_NAME) %>%
  mutate(total_events = sum(count)) %>%
  ungroup()

ggplot(region_events, 
       aes(x = count, 
           y = reorder(AREA_NAME, total_events),
           fill = EVENT_TYPE)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(title = "Event Distribution by Region (2018-2023)",
       x = "Number of Events",
       y = "Region",
       fill = "Event Type") +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 8),
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
  )
region_events
```

# Relationship between maintenance/construction and incidents

Data Preparation:

-   Considered highways only
-   Categorized events into "maintenance" (CONSTRUCTION/MAINTENANCE), "incident" (INCIDENT/COLLISION), or "other"
-   Counted events by road and category
-   Transformed data into wide format with maintenance and incident counts per road

Network Creation:

Created an adjacency matrix using distance between roads based on their maintenance/incident patterns Converted to an igraph network where:

-   Nodes represent roads
-   Edges connect roads with similar incident patterns (The code creates a distance-based network where roads are connected if they have similar numbers of maintenance events and incidents, using Euclidean distance to measure this similarity.)
-   Edge weight determined by similarity threshold (mean distance)

```{r}
#| label: fig-graph4
#| fig-width: 13
#| fig-height: 10

# filter for highways only
road_network <- road_data %>%
   filter(grepl("^(Hwy|Highway|Trans-Canada|BC-)", ROAD_NAME)) %>%
  mutate(
    event_category = case_when(
      EVENT_TYPE %in% c("CONSTRUCTION", "MAINTENANCE") ~ "maintenance",
      EVENT_TYPE %in% c("INCIDENT", "COLLISION") ~ "incident",
      TRUE ~ "other"
    )
  ) %>%
  # Count events by road and category
  group_by(ROAD_NAME, event_category) %>%
  summarise(
    count = n(),
    .groups = 'drop'
  ) %>%
  # Pivot to wide format to get maintenance and incident counts per road
  pivot_wider(
    names_from = event_category,
    values_from = count,
    values_fill = 0
  )

# Create adjacency matrix based on similar incident patterns
road_matrix <- road_network %>%
  select(maintenance, incident) %>%
  dist() %>%
  as.matrix()

g <- graph_from_adjacency_matrix(
  (road_matrix < mean(road_matrix)) * 1,
  mode = "undirected",
  weighted = TRUE
)


g <- simplify(g, remove.loops = TRUE) # need to remove self-loops as they are not meaningful

V(g)$name <- road_network$ROAD_NAME
V(g)$maintenance <- road_network$maintenance
V(g)$incidents <- road_network$incident
V(g)$ratio <- road_network$incident / (road_network$maintenance + 1)

correlation <- cor.test(road_network$maintenance, road_network$incident)

layout <- layout_on_grid(g)

incident_sizes <- log1p(V(g)$incidents)
norm_sizes <- 3 + (incident_sizes - min(incident_sizes)) / 
              (max(incident_sizes) - min(incident_sizes)) * 15

plot(g,
     layout = layout,
     vertex.size = norm_sizes,
     vertex.color = ifelse(V(g)$ratio > median(V(g)$ratio), 
                          adjustcolor("red", alpha=0.7), 
                          adjustcolor("green", alpha=0.7)),
     vertex.label.cex = 0.7,
     vertex.label.dist = 0.8,
     vertex.label.color = "black",
     vertex.frame.color = "gray50",
     edge.color = adjustcolor("gray40", alpha=0.2),
     edge.width = 0.5,
     main = paste("Road Network: Maintenance vs Incidents\n",
                 "Correlation =", round(correlation$estimate, 3)))
legend("bottomright", 
       legend=c("High incident/maintenance ratio", "Low incident/maintenance ratio"),
       fill=c(adjustcolor("red", alpha=0.7), adjustcolor("green", alpha=0.7)),
       cex=0.6,
       bty="n")

# statistical summary 
summary_stats <- road_network %>%
  summarise(
    correlation = cor(maintenance, incident),
    roads_with_high_maintenance = sum(maintenance > mean(maintenance)),
    roads_with_high_incidents = sum(incident > mean(incident))
  )

summary_stats

# Ordered list of roads and weights
road_weights <- data.frame(
  road = V(g)$name,
  incidents = V(g)$incidents,
  maintenance = V(g)$maintenance,
  ratio = V(g)$ratio
) %>%
  arrange(desc(ratio)) %>%
  mutate(
    formatted_output = sprintf(
      "%s: %.2f incidents per maintenance (incidents: %d, maintenance: %d)",
      road,
      ratio,
      incidents,
      maintenance
    )
  )

cat("\nRoads ordered by incident/maintenance ratio:\n")
cat(paste0(seq_along(road_weights$formatted_output), ". ", 
          road_weights$formatted_output, 
          collapse = "\n"))
```

The high correlation suggests that maintenance work is reactive - roads with more incidents tend to receive more maintenance, rather than maintenance preventing incidents.

-   Problem roads get more maintenance attention
-   High-traffic roads naturally have both more incidents and require more maintenance
-   Maintenance work itself could potentially increase the likelihood of incidents

# Community detection based on maintenance and incident patterns

```{r}
#| label: fig-graph5
#| fig-width: 16
#| fig-height: 8

communities <- cluster_louvain(g)
V(g)$community <- membership(communities)
n_communities <- length(unique(V(g)$community))
community_colors <- rainbow(n_communities, alpha=0.6)

par(mfrow=c(1,2), mar=c(2,2,3,2))

layout_grid <- layout_on_grid(g)
plot(g,
     layout = layout_grid,
     vertex.size = norm_sizes,
     vertex.color = community_colors[V(g)$community],
     vertex.label.cex = 0.6,
     vertex.label.dist = 1.2,
     vertex.label.color = "black",
     vertex.frame.color = "gray50",
     edge.color = adjustcolor("gray40", alpha=0.2),
     edge.width = 0.5,
     main = "Grid Layout\nBC Highway Communities")

layout_fr <- layout_with_fr(g, niter=500, grid="nogrid")
plot(g,
     layout = layout_fr,
     vertex.size = norm_sizes,
     vertex.color = community_colors[V(g)$community],
     vertex.label.cex = 0.6,
     vertex.label.dist = 1.2,
     vertex.label.color = "black",
     vertex.frame.color = "gray50",
     edge.color = adjustcolor("gray40", alpha=0.2),
     edge.width = 0.5,
     main = "Fruchterman-Reingold Layout\nBC Highway Communities")

par(mfrow=c(1,1), mar=c(5,4,4,2)+0.1)

community_sizes <- table(membership(communities))

cluster_stats <- data.frame(
  community = as.numeric(names(community_sizes)),
  cluster_size = as.numeric(community_sizes),
  avg_incidents = tapply(V(g)$incidents, V(g)$community, mean),
  avg_maintenance = tapply(V(g)$maintenance, V(g)$community, mean)
)

cluster_stats <- cluster_stats[order(-cluster_stats$cluster_size), ]

cat("\nCluster Summary:\n")
for(i in 1:nrow(cluster_stats)) {
  community_id <- cluster_stats$community[i]
  cat(sprintf("\nCluster %d (size: %d):\n", 
              community_id, 
              cluster_stats$cluster_size[i]))
  cat("Members:", paste(V(g)$name[V(g)$community == community_id], collapse=", "), "\n")
  cat(sprintf("Average incidents: %.1f\n", cluster_stats$avg_incidents[i]))
  cat(sprintf("Average maintenance: %.1f\n", cluster_stats$avg_maintenance[i]))
}
```
